{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e42b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import floor, exp, sqrt, pi, cos, sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7021e526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# Установка библиотеки sklearn\n",
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a8a62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f3a03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_2(x):\n",
    "    \"\"\"\n",
    "    Принимает число и возвращает результат его округления\n",
    "    до 2 знаков после запятой.\n",
    "    \n",
    "    Аргументы:\n",
    "        x: Число.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Результат округления числа до 2 знаков после запятой.\n",
    "    \"\"\"\n",
    "    \n",
    "    return round(x, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364ebb7",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e0114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, x_val, y_val):\n",
    "    \"\"\"\n",
    "    Оценивает точность модели по метрике «среднее отклонение от предсказанного значения».\n",
    "    \n",
    "    Аргументы:\n",
    "        model: Модель.\n",
    "        x_test: Список объектов тестовой выборки.\n",
    "        y_test: Список значений предсказываемой характеристики для объектов из тестовой выборки.\n",
    "                Значение на $i$-й позиции в списке соответствует $i$-му объекту тестовой выборки.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Возвращает точность модели.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_pred = model.predict(x_val)\n",
    "    \n",
    "    res = 0.0\n",
    "\n",
    "    for i in range(len(y_val)):\n",
    "        res += abs(y_pred[i] - y_val[i])\n",
    "    \n",
    "    return res / len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "625aa87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_solution(model, \n",
    "                         model_configs,\n",
    "                         x_train, y_train, \n",
    "                         x_val, y_val):\n",
    "    \"\"\"\n",
    "    Принимает набор конфигураций модели линейной регрессии и находит лучшую из них\n",
    "    с помощью алгоритма grid search.\n",
    "    Для оценки точности модели на валидационной выборке используется функция score_model.\n",
    "    \n",
    "    Аргументы:\n",
    "        model: Модель.\n",
    "        model_configs: Список конфигураций модели линейной регрессии.\n",
    "                       Каждая конфигурация — список номеров факторов, \n",
    "                       которые используются для обучения модели.\n",
    "        x_train: Список объектов обучающей выборки.\n",
    "        y_train: Список значений предсказываемой характеристики для объектов из обучающей выборки.\n",
    "                 Значение на $i$-й позиции в списке соответствует $i$-му объекту обучающей выборки.\n",
    "        x_val: Список объектов валидационной выборки.\n",
    "        y_val: Список значений предсказываемой характеристики для объектов из валидационной выборки.\n",
    "               Значение на $i$-й позиции в списке соответствует $i$-му объекту валидационной выборки.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Возвращает пару значений: лучшая конфигурация, точность модели с данной конфигурацией \n",
    "        на валидационной выборке.\n",
    "    \"\"\"\n",
    "\n",
    "    best_config = []\n",
    "    best_value_score = -1\n",
    "    \n",
    "    for config in model_configs:\n",
    "        x_train_local = [[row[i] for i in config] for row in x_train]\n",
    "        x_val_local = [[row[i] for i in config] for row in x_val]\n",
    "\n",
    "        model.fit(x_train_local, y_train)\n",
    "\n",
    "        score = score_model(model, x_val_local, y_val)\n",
    "\n",
    "        if (score < best_value_score or best_value_score == -1):\n",
    "            best_value_score = score\n",
    "            best_config = config\n",
    "        \n",
    "    return best_config, round_to_2(best_value_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "357cd49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_path, frac=0.9):\n",
    "    data_x_y = []\n",
    "    \n",
    "    with open(file_path) as f:\n",
    "        cnt = 0\n",
    "        \n",
    "        for line in f:\n",
    "            if cnt == 0:\n",
    "                cnt += 1\n",
    "                continue\n",
    "                \n",
    "            l = line.strip().split(',')\n",
    "            data_x_y.append(([float(x) for x in l[:-1]], float(l[-1])))  \n",
    "            \n",
    "            cnt += 1\n",
    "            \n",
    "    cut_n = floor(frac * len(data_x_y))\n",
    "            \n",
    "    train_x_y = data_x_y[:cut_n]\n",
    "    val_x_y = data_x_y[cut_n:]\n",
    "    \n",
    "    train_x, train_y = [], []\n",
    "    \n",
    "    for x, y in train_x_y:\n",
    "        train_x.append(x)\n",
    "        train_y.append(y)\n",
    "        \n",
    "    val_x, val_y = [], []\n",
    "    \n",
    "    for x, y in val_x_y:\n",
    "        val_x.append(x)\n",
    "        val_y.append(y)\n",
    "    \n",
    "    return train_x, train_y, val_x, val_y\n",
    "\n",
    "def grid_search_test():\n",
    "    def split_df_to_xs_and_ys(df):\n",
    "        xs = []\n",
    "        ys = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            xs.append([row['x1'], row['x2'], row['x3'], row['x4']])\n",
    "            ys.append(row['y'])\n",
    "            \n",
    "        return xs, ys\n",
    "        \n",
    "    data_x_train_example_1 = [[1, -33], [2, -21], [3, -34234]]\n",
    "    data_y_train_example_1 = [1, 2, 3]\n",
    "    \n",
    "    data_x_val_example_1 = [[4, -231], [5, -342341], [6, -23]]\n",
    "    data_y_val_example_1 = [4, 5, 6]\n",
    "    \n",
    "    configs_example_1 = [[0], [1]]\n",
    "    \n",
    "    res_example_1 = ([0], 0)\n",
    "    \n",
    "    assert grid_search_solution(LinearRegression(),\n",
    "                                configs_example_1,\n",
    "                                data_x_train_example_1, data_y_train_example_1,\n",
    "                                data_x_val_example_1, data_y_val_example_1) == res_example_1\n",
    "    \n",
    "    data_x_train_example_2, data_y_train_example_2, \\\n",
    "        data_x_val_example_2, data_y_val_example_2 = process_data('grid_search_test_data.csv', frac=0.9)\n",
    "    \n",
    "    configs_example_2 = [[0], [0, 1], [0, 1, 2], [2, 3], [1]]\n",
    "    \n",
    "    res_example_2 = ([0, 1, 2], 0.26)\n",
    "    \n",
    "    assert grid_search_solution(LinearRegression(),\n",
    "                                configs_example_2,\n",
    "                                data_x_train_example_2, data_y_train_example_2,\n",
    "                                data_x_val_example_2, data_y_val_example_2) == res_example_2\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02796d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест прошёл успешно!\n"
     ]
    }
   ],
   "source": [
    "grid_search_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aacba8e",
   "metadata": {},
   "source": [
    "# Метод дихотомии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93a680a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dichotomous_search_solution(f, a, b, eps):\n",
    "    \"\"\"\n",
    "    Производит поиск минимума заданной функции в заданном интервале с помощью метода дихотомии.\n",
    "    \n",
    "    Аргументы:\n",
    "        f: Функция от одного аргумента, минимум которой необходимо найти.\n",
    "        a: Левая граница интервала, в котором происходит поиск минимума.\n",
    "        b: Правая граница интервала, в котором происходит поиск минимума.\n",
    "        eps: Допустимая погрешность при поиске минимума.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Возвращает координату точки, в которой достигается минимальное значение функции.\n",
    "        Координата должна быть округлена до 2 знаков после запятой.\n",
    "    \"\"\"\n",
    "\n",
    "    a_local = a\n",
    "    b_local = b\n",
    "\n",
    "    while ((b_local - a_local) > eps * 2):\n",
    "        mean_value = (a_local + b_local) / 2\n",
    "        \n",
    "        left_mean_value = mean_value - eps / 2\n",
    "\n",
    "        right_mean_value = mean_value + eps / 2\n",
    "\n",
    "        left = f(left_mean_value)\n",
    "        right = f(right_mean_value)\n",
    "\n",
    "        if (left > right):\n",
    "            a_local = left_mean_value\n",
    "        else:\n",
    "            b_local = right_mean_value\n",
    "\n",
    "    return round_to_2((a_local + b_local) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "576aeefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dichotomous_search_test():\n",
    "    f_example_1 = lambda x: x ** 2\n",
    "    \n",
    "    a_example_1 = -2\n",
    "    b_example_1 = 5\n",
    "    eps_example_1 = 0.01\n",
    "    \n",
    "    res_example_1 = 0\n",
    "    \n",
    "    min_example_1 = dichotomous_search_solution(f_example_1, a_example_1, b_example_1, eps_example_1)\n",
    "    \n",
    "    if min_example_1 == 0.0:\n",
    "        min_example_1 = abs(min_example_1)\n",
    "    \n",
    "    assert min_example_1 == res_example_1\n",
    "    \n",
    "    f_example_2 = lambda x: (exp(2 * (x - 2)) + 1) * (x + 1) ** 2\n",
    "    \n",
    "    a_example_2 = -100\n",
    "    b_example_2 = 200\n",
    "    eps_example_2 = 0.01\n",
    "    \n",
    "    res_example_2 = -1\n",
    "    \n",
    "    min_example_2 = dichotomous_search_solution(f_example_2, a_example_2, b_example_2, eps_example_2)\n",
    "    \n",
    "    if min_example_2 == 0.0:\n",
    "        min_example_2 = abs(min_example_2)\n",
    "    \n",
    "    assert min_example_2 == res_example_2\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8b023a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест прошёл успешно!\n"
     ]
    }
   ],
   "source": [
    "dichotomous_search_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65f9ac",
   "metadata": {},
   "source": [
    "# Градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee277984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_solution(grad_f, x_0, alpha, eps):\n",
    "    \"\"\"\n",
    "    Производит поиск минимума заданной функции двух аргументов с помощью градиентного спуска.\n",
    "    \n",
    "    Аргументы:\n",
    "        grad_f: Градиент функции двух аргументов, для которой необходимо найти минимум.\n",
    "                Функция принимает на вход точку (список из двух значений) и возвращает\n",
    "                вектор градиента в этой точке (тоже список из двух значений).\n",
    "        x_0: Стартовая точка (список из двух значений), из которой запускается алгоритм градиентного спуска.\n",
    "        alpha: Коэффициент скорости обучения.\n",
    "        eps: Минимальное расстояние между текущей точкой градиентного спуска и следующей,\n",
    "             при котором работа алгоритма останавливается.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Координаты точки (список из двух значений), в которой достигается минимальное значение функции.\n",
    "        Каждая координата должна быть округлена до 2 знаков после запятой.\n",
    "    \"\"\"\n",
    "    def dist_v(x1, x2):\n",
    "        return ((x1[0] - x2[0]) ** 2 + (x1[1] - x2[1]) ** 2) ** (1/2)\n",
    "    \n",
    "    def subtraction_vector(_x, _vector):\n",
    "        x1 = _x[0] - _vector[0]\n",
    "        x2 = _x[1] - _vector[1]\n",
    "\n",
    "        return [x1, x2]\n",
    "    \n",
    "    def multiplication_vector(_x, _vector):\n",
    "        x1 = _x * _vector[0]\n",
    "        x2 = _x * _vector[1]\n",
    "\n",
    "        return [x1, x2]\n",
    "    \n",
    "    def round_coordinates(_x):\n",
    "        x1 = round_to_2(_x[0])\n",
    "        x2 = round_to_2(_x[1])\n",
    "\n",
    "        return [x1, x2]\n",
    "\n",
    "\n",
    "    x_past = x_0\n",
    "\n",
    "    x_present = subtraction_vector(x_past, multiplication_vector(alpha, grad_f(x_past)))\n",
    "\n",
    "    while(dist_v(x_present, x_past) > eps):\n",
    "        x_past = x_present\n",
    "        x_present = subtraction_vector(x_past, multiplication_vector(alpha, grad_f(x_past)))\n",
    "\n",
    "    return round_coordinates(x_present)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b731c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_test():\n",
    "    f_example_1 = lambda x: 2 * x[0] ** 2 + 2 * x[1] ** 2\n",
    "    grad_f_example_1 = lambda x: [4 * x[0], 4 * x[1]]\n",
    "    \n",
    "    x_0_example_1 = [32, -4]\n",
    "    \n",
    "    alpha_example_1 = 0.01\n",
    "    eps_example_1 = 0.001\n",
    "    \n",
    "    res_example_1 = [0.02, 0]\n",
    "    \n",
    "    assert gradient_descent_solution(grad_f_example_1, x_0_example_1, alpha_example_1, eps_example_1) == res_example_1\n",
    "    \n",
    "    f_example_2 = lambda x: (x[0] - 1) ** 4 + 2 * (x[1] + 2) ** 2 - 1\n",
    "    grad_f_example_2 = lambda x: [4 * (x[0] - 1) ** 3, 4 * (x[1] + 2)]\n",
    "    \n",
    "    x_0_example_2 = [-2, 2]\n",
    "    \n",
    "    alpha_example_2 = 0.0001\n",
    "    eps_example_2 = 0.0001\n",
    "    \n",
    "    res_example_2 = [0.58, -1.76]\n",
    "    \n",
    "    assert gradient_descent_solution(grad_f_example_2, x_0_example_2, alpha_example_2, eps_example_2) == res_example_2\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4a55763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест прошёл успешно!\n"
     ]
    }
   ],
   "source": [
    "gradient_descent_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e68b85",
   "metadata": {},
   "source": [
    "# Метод имитации отжига"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28a7759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return 2 * x ** 2 + cos(pi * x) - 2.9 * sin(2 * pi * x) + cos(3 * pi * x) * sin(pi * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18fe0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_with_p(random_gen, p, new_x, x):\n",
    "    \"\"\"\n",
    "    С заданной вероятностью возвращает точку `new_x`, в остальных случаях\n",
    "    возвращает точку x.\n",
    "    \n",
    "    Аргументы:\n",
    "        random_gen: Генератор случайных чисел.\n",
    "        p: Вероятность, с которой нужно вернуть первую точку.\n",
    "        new_x: Точка, которая возвращается с вероятностью p.\n",
    "        x: Точка, которая возвращает в остальных случаях.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Точка, которая с вероятностью p будет равна new_x. В противном случае точка будет равна x.\n",
    "    \"\"\"\n",
    "    \n",
    "    val = random_gen.random()\n",
    "    \n",
    "    if val > p:\n",
    "        return x\n",
    "    \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16e88d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing_solution(f, x_0, t_0, lam, eps, random_gen):\n",
    "    \"\"\"\n",
    "    Производит поиск минимума функции с помощью метода имитации отжига.\n",
    "    \n",
    "    Аргументы:\n",
    "        f: Функция, минимум которой необходимо найти.\n",
    "        x_0: Стартовая точка, из которой начинается процесс поиска минимума.\n",
    "        t_0: Начальная температура системы.\n",
    "        lam: Коэффициент охлаждения системы на каждом шаге.\n",
    "             Охлаждение происходит по правилу T = lam * T.\n",
    "        eps: Когда температура становится меньше eps, метод имитации отжига останавливает свою работу.\n",
    "        random_gen: Генератор случайных чисел.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Точка, которую метод считает минимумом функции.\n",
    "    \"\"\"\n",
    "    \n",
    "    T = t_0\n",
    "    x_t = x_0\n",
    "    \n",
    "    while T > eps:\n",
    "        # Случайное изменение текущей точки в пределах (-1, 1)\n",
    "        new_x = x_t + random_gen.uniform(-1, 1)\n",
    "\n",
    "        # Вычисляем разницу значений функции\n",
    "        delta_f = f(new_x) - f(x_t)\n",
    "\n",
    "        if delta_f < 0:\n",
    "            # Если новое значение функции меньше, принимаем новую точку\n",
    "            x_t = new_x\n",
    "        else:\n",
    "            # Если значение больше, принимаем с вероятностью e^(-delta_f / T)\n",
    "            prob = exp(-delta_f / T)\n",
    "            x_t = sub_with_p(random_gen, prob, new_x, x_t)\n",
    "        \n",
    "        # Охлаждаем систему\n",
    "        T *= lam\n",
    "\n",
    "    return round_to_2(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd77b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing_test():\n",
    "    weierstrass_function = lambda x: 10 + x ** 2 - 10 * cos(2 * pi * x)\n",
    "\n",
    "    f_example_1 = weierstrass_function\n",
    "    \n",
    "    x_0_example_1 = 20\n",
    "    t_0_example_1 = 1000\n",
    "    lam_example_1 = 0.99\n",
    "    eps_example_1 = 0.001\n",
    "    \n",
    "    random_gen_example_1 = random.Random(0)\n",
    "    \n",
    "    res_example_1 = 0.0\n",
    "    \n",
    "    found_min_example_1 = \\\n",
    "        simulated_annealing_solution(weierstrass_function,\n",
    "                                     x_0_example_1,\n",
    "                                     t_0_example_1,\n",
    "                                     lam_example_1,\n",
    "                                     eps_example_1,\n",
    "                                     random_gen_example_1)\n",
    "    \n",
    "    assert round_to_2(weierstrass_function(found_min_example_1)) == res_example_1\n",
    "    \n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b62b94fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест прошёл успешно!\n"
     ]
    }
   ],
   "source": [
    "simulated_annealing_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9adae322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.71\n"
     ]
    }
   ],
   "source": [
    "x_0 = 10\n",
    "t_0 = 1000\n",
    "lam = 0.99\n",
    "eps = 0.001\n",
    "random_gen = random.Random(0)\n",
    "\n",
    "found_min = simulated_annealing_solution(g,\n",
    "                                        x_0,\n",
    "                                        t_0,\n",
    "                                        lam,\n",
    "                                        eps,\n",
    "                                        random_gen)\n",
    "\n",
    "print(round_to_2(found_min))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
